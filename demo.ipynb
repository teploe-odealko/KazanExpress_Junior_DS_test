{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "demo.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNahfeMlrkvGZYulHHMLlIn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/teploe-odealko/KazanExpress_Junior_DS_test/blob/master/demo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rdghs2uVKXpc"
      },
      "source": [
        "import joblib\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ojng3fXNKT9U",
        "outputId": "a0d1a858-bd10-4de3-aadc-5f4595c91e60"
      },
      "source": [
        "!gdown https://drive.google.com/uc?id=1E7wnU9sT3WmrczdpxfwdzlZiLyZjHOX1\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1E7wnU9sT3WmrczdpxfwdzlZiLyZjHOX1\n",
            "To: /content/model.joblib\n",
            "319MB [00:03, 92.6MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "giER4BQvK-Pf"
      },
      "source": [
        "#Models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5NbqFt12LIh0"
      },
      "source": [
        "!pip install pytorch_lightning"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qog1VzNIK_g8",
        "outputId": "5465b987-cc3e-4f04-b270-37e9e651e2fb"
      },
      "source": [
        "import torch \n",
        "  \n",
        "from torch import nn \n",
        "import pytorch_lightning as pl \n",
        "import torch.nn.functional as F \n",
        "from torchvision import datasets, transforms\n",
        "from torch.optim import SGD \n",
        "from torch.utils.data import random_split, DataLoader \n",
        "from sklearn.metrics import accuracy_score\n",
        "pl.utilities.seed.seed_everything(seed=42)\n",
        "\n",
        "class ModelLayer2(pl.LightningModule): \n",
        "    def __init__(self): \n",
        "        super().__init__() \n",
        "\n",
        "        self.fc1 = nn.Linear(100, 256)\n",
        "        self.bn1 = nn.BatchNorm1d(256)\n",
        "        self.fc2 = nn.Linear(256, 128) \n",
        "        self.fc3 = nn.Linear(128, 3) \n",
        "        # self.out = nn.Linear(128, len(np.unique(y))) \n",
        "        self.lr = 0.01\n",
        "        self.loss = nn.CrossEntropyLoss()\n",
        "    \n",
        "    def forward(self, x):\n",
        "        batch_size, _, = x.size() \n",
        "        x = x.view(batch_size, -1) \n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.bn1(x)\n",
        "        x = F.relu(self.fc2(x)) \n",
        "        return self.fc3(x) \n",
        "    \n",
        "    def predict_step(self, batch, batch_idx: int , dataloader_idx: int = None):\n",
        "        self.eval()\n",
        "        return self(batch)\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        return torch.optim.SGD(self.parameters(), lr = self.lr) \n",
        "    \n",
        "    def training_step(self, train_batch, batch_idx): \n",
        "        x, y = train_batch \n",
        "        logits = self.forward(x) \n",
        "        loss = self.loss(logits, y) \n",
        "        return loss \n",
        "    \n",
        "    def validation_step(self, valid_batch, batch_idx): \n",
        "        x, y = valid_batch \n",
        "        logits = self.forward(x)\n",
        "        loss = self.loss(logits, y)\n",
        "\n",
        "        return {'pred': logits,'target': y}\n",
        "\n",
        "    def validation_epoch_end(self, outputs):\n",
        "        y = torch.cat([out['target'] for out in outputs])\n",
        "        y_hat = torch.cat([out['pred'] for out in outputs])\n",
        "        prec, recall, f1_macro, _ = precision_recall_fscore_support(\n",
        "            y.cpu(), y_hat.argmax(axis=1).cpu(), average='macro'\n",
        "            )\n",
        "        prec_weighted, recall_weighted, f1_weighted, _ = precision_recall_fscore_support(\n",
        "            y.cpu(), y_hat.argmax(axis=1).cpu(), average='weighted'\n",
        "            )\n",
        "        \n",
        "        acc = accuracy_score(y, y_hat.argmax(axis=1).cpu())\n",
        "        self.log('val_prec', prec, prog_bar=True)\n",
        "        self.log('val_recall', recall, prog_bar=True)\n",
        "        self.log('val_f1_macro', f1_macro, prog_bar=True)\n",
        "        self.log('val_f1_weighted', f1_weighted, prog_bar=True)\n",
        "        self.log('val_acc', acc, prog_bar=True)\n",
        "\n",
        "    def test_step(self, valid_batch, batch_idx): \n",
        "        x, y = valid_batch \n",
        "        logits = self.forward(x)\n",
        "        loss = self.loss(logits, y)\n",
        "\n",
        "        return {'pred': logits,'target': y}\n",
        "\n",
        "    def test_epoch_end(self, outputs):\n",
        "        y = torch.cat([out['target'] for out in outputs])\n",
        "        y_hat = torch.cat([out['pred'] for out in outputs])\n",
        "        prec, recall, f1_macro, _ = precision_recall_fscore_support(\n",
        "            y.cpu(), y_hat.argmax(axis=1).cpu(), average='macro'\n",
        "            )\n",
        "        prec_weighted, recall_weighted, f1_weighted, _ = precision_recall_fscore_support(\n",
        "            y.cpu(), y_hat.argmax(axis=1).cpu(), average='weighted'\n",
        "            )\n",
        "        \n",
        "        acc = accuracy_score(y, y_hat.argmax(axis=1).cpu())\n",
        "        self.log('test_prec', prec, prog_bar=True)\n",
        "        self.log('test_recall', recall, prog_bar=True)\n",
        "        self.log('test_f1_macro', f1_macro, prog_bar=True)\n",
        "        self.log('test_f1_weighted', f1_weighted, prog_bar=True)\n",
        "        self.log('test_acc', acc, prog_bar=True)\n",
        "  \n",
        "class ProductsCategoryDataModule(pl.LightningDataModule):\n",
        "    def __init__(self, X, y, y_strat):\n",
        "        super().__init__()\n",
        "\n",
        "        self.X = X\n",
        "        self.y = y\n",
        "        self.y_strat = y_strat\n",
        "        self.batch_size = 32\n",
        "        self.transform = transforms.Compose([\n",
        "            transforms.ToTensor()\n",
        "        ])\n",
        "  \n",
        "    def prepare_data(self):\n",
        "        pass\n",
        "        \n",
        "    def setup(self, stage=None):\n",
        "        self.train_data, self.valid_data, self.test_data = make_datasets(self.X, self.y, self.y_strat)\n",
        "\n",
        "  \n",
        "    def train_dataloader(self):\n",
        "                return DataLoader(self.train_data, \n",
        "                          batch_size = self.batch_size)\n",
        "  \n",
        "    def val_dataloader(self):\n",
        "                return DataLoader(self.valid_data,\n",
        "                          batch_size = self.batch_size)\n",
        "  \n",
        "    def test_dataloader(self):\n",
        "                return DataLoader(self.test_data,\n",
        "                          batch_size = self.batch_size)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Global seed set to 42\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GZvWpGp_LAwe"
      },
      "source": [
        "class ModelLayer3(ModelLayer2): \n",
        "    def __init__(self): \n",
        "        super().__init__()\n",
        "        # self.fc1.freeze() \n",
        "        # self.fc2.freeze() \n",
        "        # self.fc3.freeze() \n",
        "        self.fc4 = nn.Linear(3, 64)\n",
        "        self.fc5 = nn.Linear(64, 256)\n",
        "        self.bn2 = nn.BatchNorm1d(256)\n",
        "        self.fc6 = nn.Linear(256, 128)\n",
        "        self.fc7 = nn.Linear(128, 36)\n",
        "\n",
        "    def forward(self, x):\n",
        "        batch_size, _, = x.size() \n",
        "        x = x.view(batch_size, -1) \n",
        "        x = F.relu(self.fc1(x)) \n",
        "        x = F.relu(self.fc2(x)) \n",
        "        x = F.relu(self.fc3(x))\n",
        "        x = F.relu(self.fc4(x))\n",
        "        x = F.relu(self.fc5(x))\n",
        "        x = self.bn2(x)\n",
        "        x = F.relu(self.fc6(x))\n",
        "        return self.fc7(x)\n",
        "\n",
        "class ModelLayer4(ModelLayer3): \n",
        "    def __init__(self): \n",
        "        super().__init__()\n",
        "\n",
        "        self.fc8 = nn.Linear(36, 64)\n",
        "        self.fc9 = nn.Linear(64, 256)\n",
        "        self.dr1 = nn.Dropout(0.5)\n",
        "        self.fc10 = nn.Linear(256, 211)\n",
        "\n",
        "    def forward(self, x):\n",
        "        batch_size, _, = x.size() \n",
        "        x = x.view(batch_size, -1) \n",
        "        x = F.relu(self.fc1(x)) \n",
        "        x = F.relu(self.fc2(x)) \n",
        "        x = F.relu(self.fc3(x)) \n",
        "        x = F.relu(self.fc4(x)) \n",
        "        x = F.relu(self.fc5(x)) \n",
        "        x = F.relu(self.fc6(x)) \n",
        "        x = F.relu(self.fc7(x)) \n",
        "        x = F.relu(self.fc8(x)) \n",
        "        x = F.relu(self.fc9(x))\n",
        "        # x = self.dr1(x)\n",
        "        return self.fc10(x)\n",
        "\n",
        "\n",
        "class ModelLayer5(ModelLayer4): \n",
        "    def __init__(self): \n",
        "        super().__init__()\n",
        "\n",
        "        self.fc11 = nn.Linear(211, 256)\n",
        "        self.bn3 = nn.BatchNorm1d(256)\n",
        "        self.fc12 = nn.Linear(256, 512)\n",
        "        self.fc13 = nn.Linear(512, 481)\n",
        "\n",
        "    def forward(self, x):\n",
        "        batch_size, _, = x.size() \n",
        "        x = x.view(batch_size, -1) \n",
        "        x = F.relu(self.fc1(x)) \n",
        "        x = self.bn1(x)\n",
        "        x = F.relu(self.fc2(x)) \n",
        "        x = F.relu(self.fc3(x)) \n",
        "        x = F.relu(self.fc4(x)) \n",
        "        x = F.relu(self.fc5(x)) \n",
        "        x = self.bn2(x)\n",
        "        x = F.relu(self.fc6(x)) \n",
        "        x = F.relu(self.fc7(x)) \n",
        "        x = F.relu(self.fc8(x)) \n",
        "        x = F.relu(self.fc9(x))\n",
        "        x = F.relu(self.fc10(x))\n",
        "        x = F.relu(self.fc11(x))\n",
        "        x = self.bn3(x)\n",
        "        x = F.relu(self.fc12(x))\n",
        "        # x = self.dr1(x)\n",
        "        return self.fc13(x)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q0sZzjFgK2VF"
      },
      "source": [
        "class NNModel():\n",
        "    def __init__(self,\n",
        "                 model_level_4,\n",
        "                 model_level_5,\n",
        "                 mapping_level_4,\n",
        "                 mapping_level_5,\n",
        "                 category_name_df):\n",
        "        self.model_level_4 = model_level_4\n",
        "        self.model_level_5 = model_level_5\n",
        "        self.mapping_level_4 = mapping_level_4\n",
        "        self.mapping_level_5 = mapping_level_5\n",
        "        self.cat = category_name_df\n",
        "    def fit():\n",
        "        pass\n",
        "    def predict(self, x):\n",
        "        x = torch.Tensor(x).reshape(1, -1)\n",
        "\n",
        "        self.model_level_5.eval()\n",
        "        y_hat = int(self.model_level_5(x)[0].argmax().numpy())\n",
        "        category_id = self.mapping_level_5[y_hat]\n",
        "        if category_id == 0:\n",
        "            y_hat = int(self.model_level_4(x)[0].argmax().numpy())\n",
        "            category_id = self.mapping_level_4[y_hat]\n",
        "\n",
        "        category_5_level = self.cat[self.cat['category_5_level'] == category_id]\n",
        "        if (len(category_5_level) != 0):\n",
        "            category_name = category_5_level.category_title.iloc[0]\n",
        "        else:\n",
        "            category_name = self.cat[self.cat['category_4_level'] == category_id].category_title.iloc[0]\n",
        "\n",
        "        return {'category_id' : category_id, 'category_name': category_name}\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lgcexkbCKywx"
      },
      "source": [
        "class Vectorizer():\n",
        "    def __init__(self, w2v_model):\n",
        "        self.w2v_model = w2v_model\n",
        "    def preprocess_text(self, text):\n",
        "        \"\"\"Preprocess text into normalised tokens.\"\"\"\n",
        "        stop_word_list = nltk.corpus.stopwords.words('russian')\n",
        "        tokeniser = RegexpTokenizer(\"[A-Za-zА-Яа-я]+\")\n",
        "        tokens = tokeniser.tokenize(text)\n",
        "        \n",
        "        # Lowercase and lemmatise\n",
        "        # morph = pymorphy2.MorphAnalyzer()\n",
        "        # tokens_norm = [morph.parse(t.lower())[0].normal_form for t in tokens]\n",
        "        # tokens_clean = [t for t in tokens_norm if t not in stop_word_list]\n",
        "        tokens_lower = [t.lower() for t in tokens]\n",
        "        tokens_clean = [t for t in tokens_lower if t not in stop_word_list]\n",
        "        return ' '.join(tokens_clean)\n",
        "\n",
        "    def vectorize(self, text):\n",
        "        word_embs = [self.w2v_model.wv[w] for w in text.split() if w in self.w2v_model.wv]\n",
        "        if (len(word_embs) > 0):\n",
        "            return np.mean(word_embs, axis=0)\n",
        "        return np.zeros(input_size)\n",
        "\n",
        "\n",
        "    def fit():\n",
        "        pass\n",
        "        \n",
        "    def transform(self, x):\n",
        "        preprocessed = self.preprocess_text(x)\n",
        "        # print(self.w2v_model.wv[preprocessed])\n",
        "        features_x = self.vectorize(preprocessed)\n",
        "        return features_x"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2glBa9VcLaXE"
      },
      "source": [
        "#Demo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5DTKVaSqKk5z"
      },
      "source": [
        "pipeline = joblib.load('/content/model.joblib')\n"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "auE5Yu74Kn1z",
        "outputId": "ca365611-76b0-465b-80fe-52e27cc20c69"
      },
      "source": [
        "pipeline.predict('Зарядка для телефона')"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'category_id': 12171, 'category_name': 'Кабели'}"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HbVzZ0FcMh9m"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}