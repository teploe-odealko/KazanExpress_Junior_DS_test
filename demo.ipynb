{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "demo.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNChWQ9G1nRi5Pk3A79h8rT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/teploe-odealko/KazanExpress_Junior_DS_test/blob/master/demo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rdghs2uVKXpc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "de6ceb04-80bf-4c32-ecbe-b2eeee161ad0"
      },
      "source": [
        "import joblib\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ojng3fXNKT9U",
        "outputId": "8809d752-4b36-4d3c-9f33-c92ad1871376"
      },
      "source": [
        "!gdown https://drive.google.com/uc?id=1E7wnU9sT3WmrczdpxfwdzlZiLyZjHOX1\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1E7wnU9sT3WmrczdpxfwdzlZiLyZjHOX1\n",
            "To: /content/model.joblib\n",
            "319MB [00:01, 170MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "giER4BQvK-Pf"
      },
      "source": [
        "#Models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EBlzqc-HB0MZ"
      },
      "source": [
        "input_size = 100"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5NbqFt12LIh0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7e11a808-e441-42ac-9d9a-138f98bee76f"
      },
      "source": [
        "!pip install pytorch_lightning"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pytorch_lightning\n",
            "  Downloading pytorch_lightning-1.4.6-py3-none-any.whl (922 kB)\n",
            "\u001b[?25l\r\u001b[K     |▍                               | 10 kB 23.4 MB/s eta 0:00:01\r\u001b[K     |▊                               | 20 kB 27.9 MB/s eta 0:00:01\r\u001b[K     |█                               | 30 kB 32.2 MB/s eta 0:00:01\r\u001b[K     |█▍                              | 40 kB 23.2 MB/s eta 0:00:01\r\u001b[K     |█▊                              | 51 kB 9.1 MB/s eta 0:00:01\r\u001b[K     |██▏                             | 61 kB 9.4 MB/s eta 0:00:01\r\u001b[K     |██▌                             | 71 kB 7.8 MB/s eta 0:00:01\r\u001b[K     |██▉                             | 81 kB 8.7 MB/s eta 0:00:01\r\u001b[K     |███▏                            | 92 kB 8.8 MB/s eta 0:00:01\r\u001b[K     |███▌                            | 102 kB 8.1 MB/s eta 0:00:01\r\u001b[K     |████                            | 112 kB 8.1 MB/s eta 0:00:01\r\u001b[K     |████▎                           | 122 kB 8.1 MB/s eta 0:00:01\r\u001b[K     |████▋                           | 133 kB 8.1 MB/s eta 0:00:01\r\u001b[K     |█████                           | 143 kB 8.1 MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 153 kB 8.1 MB/s eta 0:00:01\r\u001b[K     |█████▊                          | 163 kB 8.1 MB/s eta 0:00:01\r\u001b[K     |██████                          | 174 kB 8.1 MB/s eta 0:00:01\r\u001b[K     |██████▍                         | 184 kB 8.1 MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 194 kB 8.1 MB/s eta 0:00:01\r\u001b[K     |███████                         | 204 kB 8.1 MB/s eta 0:00:01\r\u001b[K     |███████▌                        | 215 kB 8.1 MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 225 kB 8.1 MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 235 kB 8.1 MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 245 kB 8.1 MB/s eta 0:00:01\r\u001b[K     |████████▉                       | 256 kB 8.1 MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 266 kB 8.1 MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 276 kB 8.1 MB/s eta 0:00:01\r\u001b[K     |██████████                      | 286 kB 8.1 MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 296 kB 8.1 MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 307 kB 8.1 MB/s eta 0:00:01\r\u001b[K     |███████████                     | 317 kB 8.1 MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 327 kB 8.1 MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 337 kB 8.1 MB/s eta 0:00:01\r\u001b[K     |████████████                    | 348 kB 8.1 MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 358 kB 8.1 MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 368 kB 8.1 MB/s eta 0:00:01\r\u001b[K     |█████████████▏                  | 378 kB 8.1 MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 389 kB 8.1 MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 399 kB 8.1 MB/s eta 0:00:01\r\u001b[K     |██████████████▏                 | 409 kB 8.1 MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 419 kB 8.1 MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 430 kB 8.1 MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 440 kB 8.1 MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 450 kB 8.1 MB/s eta 0:00:01\r\u001b[K     |████████████████                | 460 kB 8.1 MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 471 kB 8.1 MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 481 kB 8.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 491 kB 8.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 501 kB 8.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 512 kB 8.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 522 kB 8.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 532 kB 8.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████▉             | 542 kB 8.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 552 kB 8.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████▌            | 563 kB 8.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 573 kB 8.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 583 kB 8.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 593 kB 8.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 604 kB 8.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 614 kB 8.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 624 kB 8.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 634 kB 8.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 645 kB 8.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 655 kB 8.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 665 kB 8.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 675 kB 8.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 686 kB 8.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 696 kB 8.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▌       | 706 kB 8.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 716 kB 8.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 727 kB 8.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 737 kB 8.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 747 kB 8.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▎     | 757 kB 8.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▋     | 768 kB 8.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 778 kB 8.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 788 kB 8.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 798 kB 8.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 808 kB 8.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 819 kB 8.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▊   | 829 kB 8.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 839 kB 8.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 849 kB 8.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 860 kB 8.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▏ | 870 kB 8.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 880 kB 8.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 890 kB 8.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 901 kB 8.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 911 kB 8.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 921 kB 8.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 922 kB 8.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning) (1.19.5)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning) (21.0)\n",
            "Collecting PyYAML>=5.1\n",
            "  Downloading PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (636 kB)\n",
            "\u001b[K     |████████████████████████████████| 636 kB 46.2 MB/s \n",
            "\u001b[?25hCollecting future>=0.17.1\n",
            "  Downloading future-0.18.2.tar.gz (829 kB)\n",
            "\u001b[K     |████████████████████████████████| 829 kB 45.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning) (3.7.4.3)\n",
            "Collecting pyDeprecate==0.3.1\n",
            "  Downloading pyDeprecate-0.3.1-py3-none-any.whl (10 kB)\n",
            "Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning) (4.62.0)\n",
            "Collecting fsspec[http]!=2021.06.0,>=2021.05.0\n",
            "  Downloading fsspec-2021.8.1-py3-none-any.whl (119 kB)\n",
            "\u001b[K     |████████████████████████████████| 119 kB 39.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorboard>=2.2.0 in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning) (2.6.0)\n",
            "Requirement already satisfied: torch>=1.6 in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning) (1.9.0+cu102)\n",
            "Collecting torchmetrics>=0.4.0\n",
            "  Downloading torchmetrics-0.5.1-py3-none-any.whl (282 kB)\n",
            "\u001b[K     |████████████████████████████████| 282 kB 44.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning) (2.23.0)\n",
            "Collecting aiohttp\n",
            "  Downloading aiohttp-3.7.4.post0-cp37-cp37m-manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.3 MB 27.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=17.0->pytorch_lightning) (2.4.7)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (0.4.5)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (1.8.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (3.3.4)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (1.34.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (0.6.1)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (0.37.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (57.4.0)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (1.39.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (1.0.1)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (3.17.3)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (0.12.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from absl-py>=0.4->tensorboard>=2.2.0->pytorch_lightning) (1.15.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard>=2.2.0->pytorch_lightning) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard>=2.2.0->pytorch_lightning) (4.7.2)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard>=2.2.0->pytorch_lightning) (4.2.2)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch_lightning) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard>=2.2.0->pytorch_lightning) (4.6.4)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard>=2.2.0->pytorch_lightning) (0.4.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning) (2021.5.30)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning) (1.24.3)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch_lightning) (3.1.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning) (21.2.0)\n",
            "Collecting multidict<7.0,>=4.5\n",
            "  Downloading multidict-5.1.0-cp37-cp37m-manylinux2014_x86_64.whl (142 kB)\n",
            "\u001b[K     |████████████████████████████████| 142 kB 62.6 MB/s \n",
            "\u001b[?25hCollecting async-timeout<4.0,>=3.0\n",
            "  Downloading async_timeout-3.0.1-py3-none-any.whl (8.2 kB)\n",
            "Collecting yarl<2.0,>=1.0\n",
            "  Downloading yarl-1.6.3-cp37-cp37m-manylinux2014_x86_64.whl (294 kB)\n",
            "\u001b[K     |████████████████████████████████| 294 kB 72.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->markdown>=2.6.8->tensorboard>=2.2.0->pytorch_lightning) (3.5.0)\n",
            "Building wheels for collected packages: future\n",
            "  Building wheel for future (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for future: filename=future-0.18.2-py3-none-any.whl size=491070 sha256=8a5d590518607110b47f3bd7127e922a6e7ff6b7fab9e552401e1c05a798b03f\n",
            "  Stored in directory: /root/.cache/pip/wheels/56/b0/fe/4410d17b32f1f0c3cf54cdfb2bc04d7b4b8f4ae377e2229ba0\n",
            "Successfully built future\n",
            "Installing collected packages: multidict, yarl, async-timeout, fsspec, aiohttp, torchmetrics, PyYAML, pyDeprecate, future, pytorch-lightning\n",
            "  Attempting uninstall: PyYAML\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "  Attempting uninstall: future\n",
            "    Found existing installation: future 0.16.0\n",
            "    Uninstalling future-0.16.0:\n",
            "      Successfully uninstalled future-0.16.0\n",
            "Successfully installed PyYAML-5.4.1 aiohttp-3.7.4.post0 async-timeout-3.0.1 fsspec-2021.8.1 future-0.18.2 multidict-5.1.0 pyDeprecate-0.3.1 pytorch-lightning-1.4.6 torchmetrics-0.5.1 yarl-1.6.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qog1VzNIK_g8",
        "outputId": "461343f8-5d6a-4437-a33a-ab7dbbb10712"
      },
      "source": [
        "import torch \n",
        "  \n",
        "from torch import nn \n",
        "import pytorch_lightning as pl \n",
        "import torch.nn.functional as F \n",
        "from torchvision import datasets, transforms\n",
        "from torch.optim import SGD \n",
        "from torch.utils.data import random_split, DataLoader \n",
        "from sklearn.metrics import accuracy_score\n",
        "pl.utilities.seed.seed_everything(seed=42)\n",
        "\n",
        "class ModelLayer2(pl.LightningModule): \n",
        "    def __init__(self): \n",
        "        super().__init__() \n",
        "\n",
        "        self.fc1 = nn.Linear(100, 256)\n",
        "        self.bn1 = nn.BatchNorm1d(256)\n",
        "        self.fc2 = nn.Linear(256, 128) \n",
        "        self.fc3 = nn.Linear(128, 3) \n",
        "        # self.out = nn.Linear(128, len(np.unique(y))) \n",
        "        self.lr = 0.01\n",
        "        self.loss = nn.CrossEntropyLoss()\n",
        "    \n",
        "    def forward(self, x):\n",
        "        batch_size, _, = x.size() \n",
        "        x = x.view(batch_size, -1) \n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.bn1(x)\n",
        "        x = F.relu(self.fc2(x)) \n",
        "        return self.fc3(x) \n",
        "    \n",
        "    def predict_step(self, batch, batch_idx: int , dataloader_idx: int = None):\n",
        "        self.eval()\n",
        "        return self(batch)\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        return torch.optim.SGD(self.parameters(), lr = self.lr) \n",
        "    \n",
        "    def training_step(self, train_batch, batch_idx): \n",
        "        x, y = train_batch \n",
        "        logits = self.forward(x) \n",
        "        loss = self.loss(logits, y) \n",
        "        return loss \n",
        "    \n",
        "    def validation_step(self, valid_batch, batch_idx): \n",
        "        x, y = valid_batch \n",
        "        logits = self.forward(x)\n",
        "        loss = self.loss(logits, y)\n",
        "\n",
        "        return {'pred': logits,'target': y}\n",
        "\n",
        "    def validation_epoch_end(self, outputs):\n",
        "        y = torch.cat([out['target'] for out in outputs])\n",
        "        y_hat = torch.cat([out['pred'] for out in outputs])\n",
        "        prec, recall, f1_macro, _ = precision_recall_fscore_support(\n",
        "            y.cpu(), y_hat.argmax(axis=1).cpu(), average='macro'\n",
        "            )\n",
        "        prec_weighted, recall_weighted, f1_weighted, _ = precision_recall_fscore_support(\n",
        "            y.cpu(), y_hat.argmax(axis=1).cpu(), average='weighted'\n",
        "            )\n",
        "        \n",
        "        acc = accuracy_score(y, y_hat.argmax(axis=1).cpu())\n",
        "        self.log('val_prec', prec, prog_bar=True)\n",
        "        self.log('val_recall', recall, prog_bar=True)\n",
        "        self.log('val_f1_macro', f1_macro, prog_bar=True)\n",
        "        self.log('val_f1_weighted', f1_weighted, prog_bar=True)\n",
        "        self.log('val_acc', acc, prog_bar=True)\n",
        "\n",
        "    def test_step(self, valid_batch, batch_idx): \n",
        "        x, y = valid_batch \n",
        "        logits = self.forward(x)\n",
        "        loss = self.loss(logits, y)\n",
        "\n",
        "        return {'pred': logits,'target': y}\n",
        "\n",
        "    def test_epoch_end(self, outputs):\n",
        "        y = torch.cat([out['target'] for out in outputs])\n",
        "        y_hat = torch.cat([out['pred'] for out in outputs])\n",
        "        prec, recall, f1_macro, _ = precision_recall_fscore_support(\n",
        "            y.cpu(), y_hat.argmax(axis=1).cpu(), average='macro'\n",
        "            )\n",
        "        prec_weighted, recall_weighted, f1_weighted, _ = precision_recall_fscore_support(\n",
        "            y.cpu(), y_hat.argmax(axis=1).cpu(), average='weighted'\n",
        "            )\n",
        "        \n",
        "        acc = accuracy_score(y, y_hat.argmax(axis=1).cpu())\n",
        "        self.log('test_prec', prec, prog_bar=True)\n",
        "        self.log('test_recall', recall, prog_bar=True)\n",
        "        self.log('test_f1_macro', f1_macro, prog_bar=True)\n",
        "        self.log('test_f1_weighted', f1_weighted, prog_bar=True)\n",
        "        self.log('test_acc', acc, prog_bar=True)\n",
        "  \n",
        "class ProductsCategoryDataModule(pl.LightningDataModule):\n",
        "    def __init__(self, X, y, y_strat):\n",
        "        super().__init__()\n",
        "\n",
        "        self.X = X\n",
        "        self.y = y\n",
        "        self.y_strat = y_strat\n",
        "        self.batch_size = 32\n",
        "        self.transform = transforms.Compose([\n",
        "            transforms.ToTensor()\n",
        "        ])\n",
        "  \n",
        "    def prepare_data(self):\n",
        "        pass\n",
        "        \n",
        "    def setup(self, stage=None):\n",
        "        self.train_data, self.valid_data, self.test_data = make_datasets(self.X, self.y, self.y_strat)\n",
        "\n",
        "  \n",
        "    def train_dataloader(self):\n",
        "                return DataLoader(self.train_data, \n",
        "                          batch_size = self.batch_size)\n",
        "  \n",
        "    def val_dataloader(self):\n",
        "                return DataLoader(self.valid_data,\n",
        "                          batch_size = self.batch_size)\n",
        "  \n",
        "    def test_dataloader(self):\n",
        "                return DataLoader(self.test_data,\n",
        "                          batch_size = self.batch_size)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Global seed set to 42\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GZvWpGp_LAwe"
      },
      "source": [
        "class ModelLayer3(ModelLayer2): \n",
        "    def __init__(self): \n",
        "        super().__init__()\n",
        "        # self.fc1.freeze() \n",
        "        # self.fc2.freeze() \n",
        "        # self.fc3.freeze() \n",
        "        self.fc4 = nn.Linear(3, 64)\n",
        "        self.fc5 = nn.Linear(64, 256)\n",
        "        self.bn2 = nn.BatchNorm1d(256)\n",
        "        self.fc6 = nn.Linear(256, 128)\n",
        "        self.fc7 = nn.Linear(128, 36)\n",
        "\n",
        "    def forward(self, x):\n",
        "        batch_size, _, = x.size() \n",
        "        x = x.view(batch_size, -1) \n",
        "        x = F.relu(self.fc1(x)) \n",
        "        x = F.relu(self.fc2(x)) \n",
        "        x = F.relu(self.fc3(x))\n",
        "        x = F.relu(self.fc4(x))\n",
        "        x = F.relu(self.fc5(x))\n",
        "        x = self.bn2(x)\n",
        "        x = F.relu(self.fc6(x))\n",
        "        return self.fc7(x)\n",
        "\n",
        "class ModelLayer4(ModelLayer3): \n",
        "    def __init__(self): \n",
        "        super().__init__()\n",
        "\n",
        "        self.fc8 = nn.Linear(36, 64)\n",
        "        self.fc9 = nn.Linear(64, 256)\n",
        "        self.dr1 = nn.Dropout(0.5)\n",
        "        self.fc10 = nn.Linear(256, 211)\n",
        "\n",
        "    def forward(self, x):\n",
        "        batch_size, _, = x.size() \n",
        "        x = x.view(batch_size, -1) \n",
        "        x = F.relu(self.fc1(x)) \n",
        "        x = F.relu(self.fc2(x)) \n",
        "        x = F.relu(self.fc3(x)) \n",
        "        x = F.relu(self.fc4(x)) \n",
        "        x = F.relu(self.fc5(x)) \n",
        "        x = F.relu(self.fc6(x)) \n",
        "        x = F.relu(self.fc7(x)) \n",
        "        x = F.relu(self.fc8(x)) \n",
        "        x = F.relu(self.fc9(x))\n",
        "        # x = self.dr1(x)\n",
        "        return self.fc10(x)\n",
        "\n",
        "\n",
        "class ModelLayer5(ModelLayer4): \n",
        "    def __init__(self): \n",
        "        super().__init__()\n",
        "\n",
        "        self.fc11 = nn.Linear(211, 256)\n",
        "        self.bn3 = nn.BatchNorm1d(256)\n",
        "        self.fc12 = nn.Linear(256, 512)\n",
        "        self.fc13 = nn.Linear(512, 481)\n",
        "\n",
        "    def forward(self, x):\n",
        "        batch_size, _, = x.size() \n",
        "        x = x.view(batch_size, -1) \n",
        "        x = F.relu(self.fc1(x)) \n",
        "        x = self.bn1(x)\n",
        "        x = F.relu(self.fc2(x)) \n",
        "        x = F.relu(self.fc3(x)) \n",
        "        x = F.relu(self.fc4(x)) \n",
        "        x = F.relu(self.fc5(x)) \n",
        "        x = self.bn2(x)\n",
        "        x = F.relu(self.fc6(x)) \n",
        "        x = F.relu(self.fc7(x)) \n",
        "        x = F.relu(self.fc8(x)) \n",
        "        x = F.relu(self.fc9(x))\n",
        "        x = F.relu(self.fc10(x))\n",
        "        x = F.relu(self.fc11(x))\n",
        "        x = self.bn3(x)\n",
        "        x = F.relu(self.fc12(x))\n",
        "        # x = self.dr1(x)\n",
        "        return self.fc13(x)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q0sZzjFgK2VF"
      },
      "source": [
        "class NNModel():\n",
        "    def __init__(self,\n",
        "                 model_level_4,\n",
        "                 model_level_5,\n",
        "                 mapping_level_4,\n",
        "                 mapping_level_5,\n",
        "                 category_name_df):\n",
        "        self.model_level_4 = model_level_4\n",
        "        self.model_level_5 = model_level_5\n",
        "        self.mapping_level_4 = mapping_level_4\n",
        "        self.mapping_level_5 = mapping_level_5\n",
        "        self.cat = category_name_df\n",
        "    def fit():\n",
        "        pass\n",
        "    def predict(self, x):\n",
        "        x = torch.Tensor(x).reshape(1, -1)\n",
        "\n",
        "        self.model_level_5.eval()\n",
        "        y_hat = int(self.model_level_5(x)[0].argmax().numpy())\n",
        "        category_id = self.mapping_level_5[y_hat]\n",
        "        if category_id == 0:\n",
        "            y_hat = int(self.model_level_4(x)[0].argmax().numpy())\n",
        "            category_id = self.mapping_level_4[y_hat]\n",
        "\n",
        "        category_5_level = self.cat[self.cat['category_5_level'] == category_id]\n",
        "        if (len(category_5_level) != 0):\n",
        "            category_name = category_5_level.category_title.iloc[0]\n",
        "        else:\n",
        "            category_name = self.cat[self.cat['category_4_level'] == category_id].category_title.iloc[0]\n",
        "\n",
        "        return {'category_id' : category_id, 'category_name': category_name}\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lgcexkbCKywx"
      },
      "source": [
        "class Vectorizer():\n",
        "    def __init__(self, w2v_model):\n",
        "        self.w2v_model = w2v_model\n",
        "    def preprocess_text(self, text):\n",
        "        \"\"\"Preprocess text into normalised tokens.\"\"\"\n",
        "        stop_word_list = nltk.corpus.stopwords.words('russian')\n",
        "        tokeniser = RegexpTokenizer(\"[A-Za-zА-Яа-я]+\")\n",
        "        tokens = tokeniser.tokenize(text)\n",
        "        \n",
        "        # Lowercase and lemmatise\n",
        "        # morph = pymorphy2.MorphAnalyzer()\n",
        "        # tokens_norm = [morph.parse(t.lower())[0].normal_form for t in tokens]\n",
        "        # tokens_clean = [t for t in tokens_norm if t not in stop_word_list]\n",
        "        tokens_lower = [t.lower() for t in tokens]\n",
        "        tokens_clean = [t for t in tokens_lower if t not in stop_word_list]\n",
        "        return ' '.join(tokens_clean)\n",
        "\n",
        "    def vectorize(self, text):\n",
        "        word_embs = [self.w2v_model.wv[w] for w in text.split() if w in self.w2v_model.wv]\n",
        "        if (len(word_embs) > 0):\n",
        "            return np.mean(word_embs, axis=0)\n",
        "        return np.zeros(input_size)\n",
        "\n",
        "\n",
        "    def fit():\n",
        "        pass\n",
        "        \n",
        "    def transform(self, x):\n",
        "        preprocessed = self.preprocess_text(x)\n",
        "        # print(self.w2v_model.wv[preprocessed])\n",
        "        features_x = self.vectorize(preprocessed)\n",
        "        return features_x"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2glBa9VcLaXE"
      },
      "source": [
        "#Demo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5DTKVaSqKk5z"
      },
      "source": [
        "pipeline = joblib.load('/content/model.joblib')\n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UBIHMvSGCBEs",
        "outputId": "bba7e635-292b-4032-a85e-4c8d168e9b57"
      },
      "source": [
        "print(pipeline.predict('Массажер для ног'))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'category_id': 11027, 'category_name': 'Массажеры для лица и тела'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "auE5Yu74Kn1z",
        "outputId": "ea1dc7ed-87b6-48b7-ec78-bd69e4b8cc53"
      },
      "source": [
        "print(pipeline.predict('Зарядка для телефона'))\n",
        "print(pipeline.predict('Пластиковая емкость для хранения'))\n",
        "print(pipeline.predict('Пластиковый контейнер'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'category_id': 12171, 'category_name': 'Кабели'}\n",
            "{'category_id': 13674, 'category_name': 'Контейнеры и ланч-боксы'}\n",
            "{'category_id': 13674, 'category_name': 'Контейнеры и ланч-боксы'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HbVzZ0FcMh9m",
        "outputId": "8cc0375a-f00f-48eb-dc5b-50ee24fa988a"
      },
      "source": [
        "print(pipeline.predict('Наушники'))\n",
        "print(pipeline.predict('Наушники для телефона'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'category_id': 12980, 'category_name': 'Беспроводные наушники'}\n",
            "{'category_id': 2803, 'category_name': 'Проводные наушники'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jz7EiJPAOHQz"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}